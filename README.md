# ComparaÃ§Ã£o EmpÃ­rica de Abordagens EstratÃ©gicas de MemoizaÃ§Ã£o versus ProgramaÃ§Ã£o Iterativa na ComputaÃ§Ã£o da Levenshtein: Topâ€‘Down Versus Bottomâ€‘Up para a DistÃ¢ncia de EdiÃ§Ã£o

**JosÃ© Ronaldo Ferreira Braga da Silva Filho**  
**Raul Santiago Pinheiro**  

GraduaÃ§Ã£o em CiÃªncia da ComputaÃ§Ã£o 2025.1 â€“ Disciplina Compiladores  
Prof.Âº Pedro Hericson Machado AraÃºjo â€“ Instituto Federal de CiÃªncia, Tecnologia e EducaÃ§Ã£o do Estado do CearÃ¡ (IFCE) â€“ MaracanaÃºâ€‘CE, Brazil  

<jose.ronaldo.ferreira07@aluno.ifce.edu.br>  
<raul.santiago.pinheiro00@aluno.ifce.edu.br>

---

## Abstract
The edit distance (or Levenshtein distance) measures the minimum number of elementary operations (insertion, removal, and replacement) required to transform one string into another. This work empirically compares two classical implementations of the algorithm: (i) a recursive topâ€‘down version with memoization and (ii) an iterative bottomâ€‘up version. Up to 5000 artificial instances of sizes 10Â â‰¤Â *n*Â â‰¤Â 5000 were generated, with 100 to 200 distinct sizes and 10 to 20 instances per size. For each pair of strings, the average execution time of both approaches was measured, ensuring the correctness of the results by crossâ€‘checking. The tests confirm the asymptotic complexity **O(nÂ²)** for both strategies, but reveal a multiplication factor of approximately ~7Ã— to ~9Ã— in the constant cost of the recursive method when *n*Â =Â 5000. The causes of this deviation â€” recursive call overhead, cache fragmentation, and stack management â€” are discussed and directions for future optimizations are pointed out.

## Resumo
A distÃ¢ncia de ediÃ§Ã£o (ou distÃ¢ncia de Levenshtein) mede o mÃ­nimo de operaÃ§Ãµes elementares (inserÃ§Ã£o, remoÃ§Ã£o e substituiÃ§Ã£o) necessÃ¡rias para transformar uma cadeia de caracteres em outra. Este trabalho compara, de forma empÃ­rica, duas implementaÃ§Ãµes clÃ¡ssicas do algoritmo: (i) uma versÃ£o topâ€‘down recursiva com memoizaÃ§Ã£o e (ii) uma versÃ£o bottomâ€‘up iterativa. Foram geradas atÃ© 5000 instÃ¢ncias artificiais de tamanhos 10Â â‰¤Â *n*Â â‰¤Â 5â€¯000, com 100 a 200 tamanhos distintos e 10 a 20 instÃ¢ncias por tamanho. Para cada par de cadeias, mediuâ€‘se o tempo mÃ©dio de execuÃ§Ã£o de ambas as abordagens, garantindoâ€‘se a correÃ§Ã£o dos resultados por verificaÃ§Ã£o cruzada. Os testes confirmam a complexidade assintÃ³tica **O(nÂ²)** para as duas estratÃ©gias, mas revelam um fator de multiplicaÃ§Ã£o de aproximadamente ~7Ã— a ~9Ã— no custo constante do mÃ©todo recursivo quando *n*Â =Â 5â€¯000. Discutemâ€‘se as causas desse desvio â€” sobrecarga de chamadas recursivas, fragmentaÃ§Ã£o de cache e gestÃ£o de pilha â€” e apontamâ€‘se direÃ§Ãµes para otimizaÃ§Ãµes futuras.

**Palavrasâ€‘chave:** distÃ¢ncia de ediÃ§Ã£o, programaÃ§Ã£o dinÃ¢mica, memoization, avaliaÃ§Ã£o experimental, complexidade de algoritmos.

---

## 1Â Â IntroduÃ§Ã£o
A distÃ¢ncia de Levenshtein Ã© amplamente empregada em bioinformÃ¡tica, correÃ§Ã£o ortogrÃ¡fica e recuperaÃ§Ã£o de informaÃ§Ã£o. Embora existam variantes subquadrÃ¡ticas para casos especÃ­ficos, a formulaÃ§Ã£o clÃ¡ssica permanece relevante em aplicaÃ§Ãµes em que simplicidade e generalidade superam necessidades de desempenho extremo. Entre as implementaÃ§Ãµes, duas famÃ­lias despontam:

* **Topâ€‘down com memoizaÃ§Ã£o** â€“ defineâ€‘se a recorrÃªncia e armazenaâ€‘se cada subproblema jÃ¡ resolvido, evitando recomputaÃ§Ãµes.  
* **Bottomâ€‘up iterativo** â€“ preencheâ€‘se explicitamente a tabela dinÃ¢mica, partindo dos casosâ€‘base.

Na teoria, ambas exigem Î˜(*nÂ·m*) em tempo e espaÃ§o, mas diferem em sobrecarga prÃ¡tica. Este artigo quantifica tal diferenÃ§a.

---

## 2Â Â Metodologia

### 2.1Â Â Algoritmos
ListagensÂ 1 eÂ 2 (ApÃªndiceÂ A) reproduzem as duas versÃµes em Python. A implementaÃ§Ã£o topâ€‘down ajusta a profundidade da pilha via `sys.setrecursionlimit`, enquanto a bottomâ€‘up explora reutilizaÃ§Ã£o de linhas da matriz para maior localidade de cache.

### 2.2Â Â GeraÃ§Ã£o dos dados
* **Alfabeto:** `a`â€“`z`.  
* **Tamanhos (*n*):** *k* valores igualmente espaÃ§ados entre 10 e 5â€¯000, onde *k*â€¯~â€¯ğ’°(100,â€¯200).  
* **InstÃ¢ncias por tamanho (*m*):** *m*â€¯~â€¯ğ’°(10,â€¯20).  
* **Reprodutibilidade:** `random.seed(42)`.

### 2.3Â Â Procedimento
Para cada tamanho *n*:

1. Gerar *m* pares de cadeias aleatÃ³rias.  
2. Executar **ambos** os algoritmos sobre os mesmos pares.  
3. Registrar `time.perf_counter()` antes/depois de cada chamada.  
4. Validar `d_memo == d_bottom` via `assert`.

### 2.4Â Â Ambiente de teste
* CPUÂ IntelÂ i7â€‘11700 (8Â c/16Â t,Â 2.5â€“4.9â€¯GHz)  
* 32Â GBÂ DDR4â€‘3200  
* PythonÂ 3.12, matplotlibÂ 3.9  
* GoogleÂ ColabÂ CPU

---

## 3Â Â Resultados

![FiguraÂ 1 â€” Resultado Bruto por instÃ¢ncia dos algoritmos topâ€‘down e bottomâ€‘up (*k*Â =Â 181,Â *m*Â =Â 11).](figura1.png)
![TabelaÂ 1 â€” Algumas Amostras do tempo mÃ©dio por algoritmos topâ€‘down e bottomâ€‘up (*k*Â =Â 181,Â *m*Â =Â 11).](tabela1.png)


Ambas as curvas seguem crescimento aproximadamente quadrÃ¡tico, mas a inclinaÃ§Ã£o da versÃ£o recursiva Ã© marcadamente superior.

---

## 4Â Â DiscussÃ£o

1. **Sobrecarga de chamadas recursivas** â€“ cada subproblema dispara trÃªs chamadas; apesar da memoizaÃ§Ã£o evitar recomputaÃ§Ãµes, o empilhamento/desempilhamento adiciona custo notÃ¡vel.  
2. **Localidade de cache** â€“ o acesso linhaâ€‘aâ€‘linha do bottomâ€‘up percorre a matriz em ordem previsÃ­vel, favorecendo caching. A versÃ£o recursiva visita cÃ©lulas numa ordem guiada por dependÃªncias que, embora menor em visitas totais, causa saltos de memÃ³ria.  
3. **GestÃ£o de pilha** â€“ o limite da pilha foi elevado para atÃ© 100â€¯000 frames em entradas grandes; a reserva/desâ€‘reserva de pilha Ã© cara e pode acionar *page faults*.  
4. **Risco de estouro de pilha** â€“ sistemas com limites menores podem falhar na versÃ£o recursiva, revelando impacto nÃ£o apenas em desempenho, mas em robustez.

Os dados sugerem que, para valores prÃ¡ticos de *n* acima de algumas centenas (â‰ˆâ€¯350), o bottomâ€‘up Ã© preferÃ­velÂ â€” contrariando a intuiÃ§Ã£o de que eliminar iteraÃ§Ã£o explÃ­cita poderia ser mais rÃ¡pido.

---

## 5Â Â ConclusÃ£o e Trabalhos Futuros
Confirmouâ€‘se a equivalÃªncia funcional das duas abordagens e comprovouâ€‘se empiricamente a superioridade de desempenho da versÃ£o bottomâ€‘up em torno de atÃ© ~9Â vezes. Futuras investigaÃ§Ãµes podem abranger:

* OtimizaÃ§Ãµes de espaÃ§o (usaâ€‘se apenas duas linhas da matriz).  
* Emprego de tÃ©cnicas subquadrÃ¡ticas (p.â€¯ex., Myersâ€¯/â€¯O(ND)).  
* AvaliaÃ§Ã£o em outros alfabetos (DNA, Unicode) e perfis de similaridade parcial.  
* ParalelizaÃ§Ã£o em GPU e SIMD (Single Instruction, Multiple Data).

---

## ReferÃªncias

CORMEN, T.Â H.; LEISERSON, C.Â E.; RIVEST, R.Â L.; STEIN, C. *Introduction to Algorithms.* 3.ÂªÂ ed. MITÂ Press, 2009.  
LEVENSHTEIN, V.Â I. Binary codes capable of correcting deletions, insertions and reversals. *Soviet Physics Doklady*, 10â€¯(8):Â 707â€‘710,Â 1966.  
WAGNER, R.Â A.; FISCHER, M.Â J. The stringâ€‘toâ€‘string correction problem. *Journal of the ACM*, 21â€¯(1):Â 168â€‘173,Â 1974.  
MYERS, G.Â A. A fast bitâ€‘vector algorithm for approximate string matching based on dynamic programming. *Journal of the ACM*, 46â€¯(3):Â 395â€‘415,Â 1999.
